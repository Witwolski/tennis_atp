{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "devengine = create_engine(\"sqlite:///C:/Git/tennis_atp/database/bets_sqllite.db\")\n",
    "time_now = datetime.datetime.now()\n",
    "time_now_formatted = time_now.strftime(\"%Y-%m-%d\")\n",
    "data=pd.read_sql_query(\"Select distinct * from results_hard_1 --where date > '2023-04-24'\",con=devengine)\n",
    "data[\"Fav_Odds\"] = data.Fav_Odds.astype(float)\n",
    "data[\"Dog_Odds\"] = data.Dog_Odds.astype(float)\n",
    "\n",
    "\n",
    "#data=(data[(data['Fav_Odds']<=1.3)&(data['Fav_Odds']>=1.08)])\n",
    "data[data['Elo_Fav_Elo']>2000].sort_values(by='Elo_Fav_Elo').tail(20)\n",
    "#data[data['Dog']=='Daniil Medvedev']\n",
    "pd.read_sql_query(\"Select distinct * from AllMatches --where date > '2023-04-24'\",con=devengine).to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.copy()\n",
    "test_data['Winner_Dog'] = test_data['Dog'] == test_data['Winner']\n",
    "test_data['Winner_EloDog'] = test_data['Elo_Fav'] != test_data['Winner']\n",
    "column_order = ['Winner_Dog', 'Winner_EloDog'] + [col for col in test_data if col not in ['Winner_Dog', 'Winner_EloDog']]\n",
    "test_data = test_data[column_order]\n",
    "test_data=test_data.drop(columns=['Winner','Fav','Elo_Fav','Dog','Resulted','Winner_Odds','Fav_Odds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Winner_Dog: 0.8644859813084113\n",
      "Accuracy for Winner_EloDog: 0.8084112149532711\n",
      "Classification Report for Winner_Dog:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      1.00      0.93       185\n",
      "        True       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.86       214\n",
      "   macro avg       0.43      0.50      0.46       214\n",
      "weighted avg       0.75      0.86      0.80       214\n",
      "\n",
      "Classification Report for Winner_EloDog:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.98      0.89       166\n",
      "        True       0.77      0.21      0.33        48\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.79      0.60      0.61       214\n",
      "weighted avg       0.80      0.81      0.76       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming your data is stored in a DataFrame named 'data'\n",
    "# You may need to adjust column names accordingly\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = test_data[[ 'fav_percent', 'dog_percent','fav_rank', 'dog_rank', 'Elo_Fav_Elo', 'Elo_Dog_Elo', 'Fav_Top100', 'Dog_Top100']]\n",
    "y_dog = test_data['Winner_Dog']\n",
    "y_elodog =test_data['Winner_EloDog']\n",
    "\n",
    "# Convert categorical variable 'Sex' to numerical using one-hot encoding\n",
    "#X = pd.get_dummies(X, columns=['Sex'], drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_dog, X_test_dog, y_train_dog, y_test_dog = train_test_split(X, y_dog, test_size=0.2, random_state=42)\n",
    "X_train_elodog, X_test_elodog, y_train_elodog, y_test_elodog = train_test_split(X, y_elodog, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression models\n",
    "model_dog = LogisticRegression()\n",
    "model_elodog = LogisticRegression()\n",
    "\n",
    "# Initialize logistic regression models with increased max_iter\n",
    "model_dog = LogisticRegression(max_iter=100000)\n",
    "model_elodog = LogisticRegression(max_iter=100000)\n",
    "\n",
    "# Train the models\n",
    "model_dog.fit(X_train_dog, y_train_dog)\n",
    "model_elodog.fit(X_train_elodog, y_train_elodog)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_dog = model_dog.predict(X_test_dog)\n",
    "y_pred_elodog = model_elodog.predict(X_test_elodog)\n",
    "\n",
    "# Evaluate the models\n",
    "accuracy_dog = accuracy_score(y_test_dog, y_pred_dog)\n",
    "accuracy_elodog = accuracy_score(y_test_elodog, y_pred_elodog)\n",
    "\n",
    "print(f\"Accuracy for Winner_Dog: {accuracy_dog}\")\n",
    "print(f\"Accuracy for Winner_EloDog: {accuracy_elodog}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"Classification Report for Winner_Dog:\")\n",
    "print(classification_report(y_test_dog, y_pred_dog))\n",
    "\n",
    "print(\"Classification Report for Winner_EloDog:\")\n",
    "print(classification_report(y_test_elodog, y_pred_elodog))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fav_win_percent_grt_10'] = data['fav_percent'] > 0.1\n",
    "data['fav_win_percent_grt_20'] = data['fav_percent'] > 0.2\n",
    "data['fav_win_percent_grt_30'] = data['fav_percent'] > 0.3\n",
    "data['fav_win_percent_grt_40'] = data['fav_percent'] > 0.4\n",
    "data['fav_win_percent_grt_50'] = data['fav_percent'] > 0.5\n",
    "data['fav_win_percent_grt_60'] = data['fav_percent'] > 0.6\n",
    "data['fav_win_percent_grt_70'] = data['fav_percent'] > 0.7\n",
    "data['fav_win_percent_grt_80'] = data['fav_percent'] > 0.8\n",
    "data['fav_win_percent_grt_90'] = data['fav_percent'] > 0.9\n",
    "data['fav_win_percent_100'] = data['fav_percent'] == 1.0\n",
    "data['dog_win_percent_grt_10'] = data['dog_percent'] > 0.1\n",
    "data['dog_win_percent_grt_20'] = data['dog_percent'] > 0.2\n",
    "data['dog_win_percent_grt_30'] = data['dog_percent'] > 0.3\n",
    "data['dog_win_percent_grt_40'] = data['dog_percent'] > 0.4\n",
    "data['dog_win_percent_grt_50'] = data['dog_percent'] > 0.5\n",
    "data['dog_win_percent_grt_60'] = data['dog_percent'] > 0.6\n",
    "data['dog_win_percent_grt_70'] = data['dog_percent'] > 0.7\n",
    "data['dog_win_percent_grt_80'] = data['dog_percent'] > 0.8\n",
    "data['dog_win_percent_grt_90'] = data['dog_percent'] > 0.9\n",
    "data['dog_win_percent_100'] = data['dog_percent'] == 1.0\n",
    "\n",
    "data['fav_win_percent_lt_10'] = data['fav_percent'] < 0.1\n",
    "data['fav_win_percent_lt_20'] = data['fav_percent'] < 0.2\n",
    "data['fav_win_percent_lt_30'] = data['fav_percent'] < 0.3\n",
    "data['fav_win_percent_lt_40'] = data['fav_percent'] < 0.4\n",
    "data['fav_win_percent_lt_50'] = data['fav_percent'] < 0.5\n",
    "data['fav_win_percent_lt_60'] = data['fav_percent'] < 0.6\n",
    "data['fav_win_percent_lt_70'] = data['fav_percent'] < 0.7\n",
    "data['fav_win_percent_lt_80'] = data['fav_percent'] < 0.8\n",
    "data['fav_win_percent_lt_90'] = data['fav_percent'] < 0.9\n",
    "data['fav_win_percent_0'] = data['fav_percent'] == 0.0\n",
    "\n",
    "data['dog_win_percent_lt_10'] = data['dog_percent'] < 0.1\n",
    "data['dog_win_percent_lt_20'] = data['dog_percent'] < 0.2\n",
    "data['dog_win_percent_lt_30'] = data['dog_percent'] < 0.3\n",
    "data['dog_win_percent_lt_40'] = data['dog_percent'] < 0.4\n",
    "data['dog_win_percent_lt_50'] = data['dog_percent'] < 0.5\n",
    "data['dog_win_percent_lt_60'] = data['dog_percent'] < 0.6\n",
    "data['dog_win_percent_lt_70'] = data['dog_percent'] < 0.7\n",
    "data['dog_win_percent_lt_80'] = data['dog_percent'] < 0.8\n",
    "data['dog_win_percent_lt_90'] = data['dog_percent'] < 0.9\n",
    "data['dog_win_percent_0'] = data['dog_percent'] == 0.0\n",
    "\n",
    "\n",
    "# Assuming your DataFrame is called 'data' and the rank columns are 'fav_rank' and 'dog_rank'\n",
    "data['fav_rank_band'] = pd.cut(data['fav_rank'], bins=list(range(0, 201, 20)), labels=list(range(20, 201, 20)), right=False)\n",
    "data['dog_rank_band'] = pd.cut(data['dog_rank'], bins=list(range(0, 201, 20)), labels=list(range(20, 201, 20)), right=False)\n",
    "\n",
    "data['fav_rank_band'] = data['fav_rank_band'].astype(float)\n",
    "data['dog_rank_band'] = data['dog_rank_band'].astype(float)\n",
    "\n",
    "for i in range(0, 201, 50):\n",
    "    data[f'fav_rank_gt_{i}'] = data['fav_rank_band'] > i\n",
    "    data[f'fav_rank_lt_{i}'] = data['fav_rank_band'] < i\n",
    "\n",
    "    data[f'dog_rank_gt_{i}'] = data['dog_rank_band'] > i\n",
    "    data[f'dog_rank_lt_{i}'] = data['dog_rank_band'] < i\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['Winner_']=data['Winner']\n",
    "data['Winner_IsFav']=data['Winner']==data['Fav']\n",
    "data['Fav_IsEloFav']=data['Fav']==data['Elo_Fav']\n",
    "data['Female']=data['Sex']=='Womens'\n",
    "data['Male']=data['Sex']=='Mens'\n",
    "raw_data=data\n",
    "data=data[(data['Fav_Odds']>=1.6)&(data['Fav_Odds']<=2)]\n",
    "data=data[['fav_win_percent_grt_10',\n",
    "       'fav_win_percent_grt_20', 'fav_win_percent_grt_30',\n",
    "       'fav_win_percent_grt_40', 'fav_win_percent_grt_50',\n",
    "       'fav_win_percent_grt_60', 'fav_win_percent_grt_70',\n",
    "       'fav_win_percent_grt_80', 'fav_win_percent_grt_90',\n",
    "       'fav_win_percent_100',\n",
    "       'dog_win_percent_grt_20', 'dog_win_percent_grt_30',\n",
    "       'dog_win_percent_grt_40', 'dog_win_percent_grt_50',\n",
    "       'dog_win_percent_grt_60', 'dog_win_percent_grt_70',\n",
    "        'dog_win_percent_grt_90',\n",
    "       'dog_win_percent_100', 'fav_win_percent_lt_10', 'fav_win_percent_lt_20',\n",
    "       'fav_win_percent_lt_30', 'fav_win_percent_lt_40',\n",
    "       'fav_win_percent_lt_50', 'fav_win_percent_lt_60',\n",
    "       'fav_win_percent_lt_70', 'fav_win_percent_lt_80',\n",
    "       'fav_win_percent_lt_90', 'fav_win_percent_0', 'dog_win_percent_lt_10',\n",
    "       'dog_win_percent_lt_20', 'dog_win_percent_lt_30',\n",
    "       'dog_win_percent_lt_40', 'dog_win_percent_lt_50',\n",
    "       'dog_win_percent_lt_60', 'dog_win_percent_lt_70',\n",
    "       'dog_win_percent_lt_80', 'dog_win_percent_lt_90', 'dog_win_percent_0',\n",
    "        'Winner_IsFav',   'Male', 'fav_rank_gt_0',\n",
    " 'fav_rank_lt_0',\n",
    " 'dog_rank_gt_0',\n",
    " 'dog_rank_lt_0',\n",
    " 'fav_rank_gt_50',\n",
    " 'fav_rank_lt_50',\n",
    " 'dog_rank_gt_50',\n",
    " 'dog_rank_lt_50',\n",
    " 'fav_rank_gt_100',\n",
    " 'fav_rank_lt_100',\n",
    " 'dog_rank_gt_100',\n",
    " 'dog_rank_lt_100',\n",
    " 'fav_rank_gt_150',\n",
    " 'fav_rank_lt_150',\n",
    " 'dog_rank_gt_150',\n",
    " 'dog_rank_lt_150',\n",
    " 'fav_rank_gt_200',\n",
    " 'fav_rank_lt_200',\n",
    " 'dog_rank_gt_200',\n",
    " 'dog_rank_lt_200','dog_percent','Fav_Top100','Dog_Top100']]\n",
    "\n",
    "datax=data[['Winner_IsFav','fav_win_percent_grt_70',\n",
    " 'fav_win_percent_lt_60',\n",
    " 'fav_win_percent_grt_50',\n",
    " 'fav_win_percent_grt_20',\n",
    " 'fav_win_percent_lt_20']]\n",
    "raw_data.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6 1.7\n"
     ]
    }
   ],
   "source": [
    "raw_data[raw_data['Sex']=='Mens']\n",
    "for x in range(160,170,10):\n",
    "    y=x+10\n",
    "    #for y in range(105,205,5):\n",
    "    lower=x/100\n",
    "    higher=y/100\n",
    "    print(lower,higher)\n",
    "    filter=raw_data[(raw_data['Fav_Odds']>=1.6)&(raw_data['Fav_Odds']<=2)]\n",
    "    for feature in filter.columns:    \n",
    "        test=filter[filter[feature]==True]\n",
    "        \n",
    "        if len(test)>5 and feature != 'Winner_IsFav':\n",
    "            perc=(len(test[test['Winner_IsFav']==False])/len(test))\n",
    "            \n",
    "            if perc>0.5:\n",
    "                \n",
    "                print(feature,\" ({:.1%})\".format(len(test[test['Winner_IsFav']==False])/len(test)),len(test))\n",
    "                #print(\"{:.1%}\".format(len(test[test['Winner_IsFav']==True])/len(test)),len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.1\n",
      "1.1 1.2\n",
      "1.2 1.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 1.4\n",
      "1.4 1.5\n",
      "1.5 1.6\n",
      "1.6 1.7\n",
      "1.7 1.8\n",
      "1.8 1.9\n",
      "1.9 2.0\n"
     ]
    }
   ],
   "source": [
    "#raw_data[raw_data['Sex']=='Womens']\n",
    "for x in range(100,200,10):\n",
    "    y=x+10\n",
    "    #for y in range(105,205,5):\n",
    "    lower=x/100\n",
    "    higher=y/100\n",
    "    print(lower,higher)\n",
    "    filter=raw_data[(raw_data['Fav_Odds']>=lower)&(raw_data['Fav_Odds']<=higher)]\n",
    "    for feature in filter.columns:    \n",
    "        test=filter[filter[feature]==True]\n",
    "        \n",
    "        if len(test)>100 and feature != 'Winner_IsFav':\n",
    "            perc=(len(test[test['Winner_IsFav']==False])/len(test))\n",
    "            \n",
    "            if perc>0.50:\n",
    "                \n",
    "                print(feature,\" ({:.1%})\".format(len(test[test['Winner_IsFav']==False])/len(test)),len(test))\n",
    "                #print(\"{:.1%}\".format(len(test[test['Winner_IsFav']==True])/len(test)),len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lower=1.5\n",
    "higher=2\n",
    "print(lower,higher)\n",
    "filter=raw_data[(raw_data['Fav_Odds']>=lower)&(raw_data['Fav_Odds']<=higher)]\n",
    "for feature in filter.columns:    \n",
    "    test=filter[filter[feature]==True]\n",
    "    \n",
    "    if len(test)>10 and feature != 'Winner_IsFav':\n",
    "        perc=(len(test[test['Winner_IsFav']==True])/len(test))\n",
    "        \n",
    "        if perc>0.6:\n",
    "            \n",
    "            print(feature,\" ({:.1%})\".format(len(test[test['Winner_IsFav']==True])/len(test)),len(test))\n",
    "            #print(\"{:.1%}\".format(len(test[test['Winner_IsFav']==True])/len(test)),len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "(94.9%) 39\n"
     ]
    }
   ],
   "source": [
    "lower=1\n",
    "higher=2\n",
    "print(lower,higher)\n",
    "filter=raw_data[(raw_data['Fav_Odds']>=lower)&(raw_data['Fav_Odds']<=higher)]\n",
    "filter1=filter['fav_win_percent_grt_60']\n",
    "filter2=filter['dog_win_percent_lt_20']\n",
    "test=filter[filter1&filter2]\n",
    "\n",
    "if len(test)>1:\n",
    "    perc=(len(test[test['Winner_IsFav']==True])/len(test))\n",
    "    \n",
    "    if perc>0:\n",
    "        \n",
    "        print(\"({:.1%})\".format(len(test[test['Winner_IsFav']==True])/len(test)),len(test))\n",
    "        #print(\"{:.1%}\".format(len(test[test['Winner_IsFav']==True])/len(test)),len(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
